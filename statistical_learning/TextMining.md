### 文本挖掘

- 文本挖掘的**两个阶段**
  - 第一阶段：文本处理
  - 第二阶段：数据挖掘建模

- 特征选择
  - 最基本：根据词频进行特征选择
  - 其他

#### 文本聚类

&emsp;&emsp;对文档（每一行）按照相似性进行分组，可以解释文档间的内在语义结构

&emsp;&emsp;文本聚类是模型中的描述部分，文本分类则是预测建模过程

##### **文本聚类的方法**

  - 基于相似度的方法
    - 用户显示的定义一个相似度的函数，每个文本只属于一类，即“硬聚类”
  - 基于模型的方法
    - 并不要求每个文本只属于一个组，而是给出一个文本属于各组的概率，即“软聚类”，典型代表：话题检测

- *K-Means* （基于相似度的方法）

- *高斯混合模型*　（基于模型的软聚类方法）

  - 和K-Means一样，也是一种通过迭代求解的方法
  - 高斯分布的混合 $p(x)=\sum_{i=1}^{k} \omega_i g(x|\mu_i, \sum_i)$
  - 利用似然函数作为目标函数对GMM进行参数估计
  - 无法求导解，需要先猜测各成分的权重，然后通过迭代的方式收敛到局部最优解

- *EM算法*
  - 假设各成分的概率已知，使得极大似然函数可求导
  - 利用后验概率作为各成分概率的估计值，求解参数
  - 进行迭代，最终收敛到局部最优解


##### 话题检测
  - 找出文档中的k个话题，并计算每个文档对每个话题的覆盖率
  - 话题的表示方法
    - 基于单个词的话题表示方法
    - 基于词分布的话题表示法

  - 问题的正确定义如下：
    - 输入：
      - 由N个文档构成的文本集C
      - 话题个数k
      - 词典V
    - 输出：
      - k个话题的分布($\theta_1,\theta_2,...,\theta_k$)
      - 每个文档在不同话题上的概率分布($\pi_1,...,\pi_N$)
  
&emsp;&ensp;根据训练集估计这些参数，即利用生成模型进行文本挖掘的常用思路。

- 多文档多主题情况：PLSA方法
  - 为了降低停用词的概率，需要额外考虑一个背景词分布
- 给PLSA增加先验
  - 在话题的词分布上增加先验
    - 如果用户表现出对某些特定话题的兴趣，可以增加特定话题的先验
    - 添加先验的方式
      - MAP估计，采用共轭先验信息，类似MLE
    　- 先验的系数控制了先验的强弱
  - 在文档的话题覆盖上增加先验
- PLSA的不足：
&emsp;没办法给一个看不见的文档（新文档）估计概率

- LDA模型
  - 假设每一个先验都服从Dirichlet分布，这样显著减少了参数个数
  - 仍然利用MLE估计参数



