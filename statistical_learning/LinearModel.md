## 统计机器学习算法整理

    整理思路

    《统计学习方法》过一遍，把从书上提炼出来的东西做一下整合和展
    开，可以结合一些之前做过的作业和总结的资料；最后看一遍cs229查漏补缺

----

- 大纲

1. 统计学习概念（《统计学习方法》第一章）

1. 线性模型

1. 广义线性模型

### 1、统计学习概念

- <font color=red>统计学习方法的三要素：模型、策略、算法</font>
- 模型评价和模型选择
- 统计学习包括：监督学习、非监督学习、半监督学习、强化学习
我们主要讨论监督学习的问题。

#### 三要素
**模型：**

* 分为
  * 非概率模型：由决策函数表示的模型
  * 概率模型：由条件概率表示的模型

**策略：**

- 期望风险最小化
- 经验风险最小化/结构风险最小化

- `举例`：
  - 极大似然估计属于经验风险最小化
  - 最大后验概率估计属于结构风险最小化

**算法：**

是指学习模型的具体计算方法。

#### 模型评价和模型选择

**正则化**
通过正则化减小测试误差

`正则化及其bayes解释:` 解释常见正则L1,L2范数及其解法（最优化）；正则化的bayes解释。解释为什么正则化可以起到防止过拟合的作用？解释为什么L1正则可以起到筛选变量的作用？（薛薇ppt）

**交叉验证**
可以通过交叉验证的方法选取测试误差最小的模型（李航）

**训练误差和测试误差**
`推导:`可参考薛薇/宋捷课件。

**偏差-方差权衡** (薛薇ppt)
`MSE的分解` $$E(y_0 - \hat{f}(x_0))^2 = Var(\hat{f}(x_0)) + [Bias(\hat{f}(x_0))]^2 + Var(\epsilon).$$

**泛化能力**
- 泛化误差：就是模型的期望风险
- 泛化误差上界：用于评价模型的泛化能力

`Tips`
1. 通过正则化/交叉验证选出的测试误差最小的模型一定是泛化能力最强的模型？  不一定。这两个评价标准不完全一致。

#### 统计学习的几大类问题

**生成模型和判别模型**
- 生成方法的特点：生成方法学习的是$P(X,Y)$，比如：朴素贝叶斯、隐马尔可夫
- 判别方法的特点：学习的是$P(Y|X) or f(X)$，比如：常见的机器学习方法

**统计学习的几大类问题**
1. 分类问题
   - 分类器： $P(Y|X) or f(X)$，关注的类设为正类
   - 评价指标
   - 常用方法

1. 标注问题
   - 分为学习和标注两个过程
   - 学习器：$P(Y|X)$
   - 常用方法：隐马尔可夫、条件随机场

1. 回归问题
   - 分为学习和预测两个过程
   - `线性回归的求解：Least Square / SGD`
   - `逻辑回归的求解`

### 2、线性模型

#### LR及其推导

**逻辑回归和极大似然估计**

- 李航

**逻辑回归的求解**

- 李航
- https://www.jianshu.com/p/631a3fe4542e

**优化算法**

- `牛顿法、拟牛顿等`

- 最优化相关资料

### 3、广义线性模型（GLM）

逻辑回归和线性回归都属于广义线性模型，下面我们详细介绍。

参考：

https://www.zhihu.com/question/35322351

https://hyzhan.github.io/2017/05/23/2017-05-23-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92LR%E6%8E%A8%E5%AF%BC%EF%BC%88sigmoid%EF%BC%8C%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%EF%BC%8C%E6%A2%AF%E5%BA%A6%EF%BC%8C%E5%8F%82%E6%95%B0%E6%9B%B4%E6%96%B0%E5%85%AC%E5%BC%8F%EF%BC%89/

